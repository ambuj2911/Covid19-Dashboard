{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "\n",
    "%matplotlib inline\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "from plotly.subplots import make_subplots\n",
    "import cufflinks as cf\n",
    "from plotly.offline import init_notebook_mode,plot,iplot \n",
    "\n",
    "import folium # for maps\n",
    "\n",
    "from zipfile import ZipFile \n",
    "import seaborn as sns\n",
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "#import geopandas as gpd\n",
    "import os\n",
    "import kaggle\n",
    "from time import time,sleep\n",
    "from random import randint\n",
    "from IPython.core.display import clear_output\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen as uReq\n",
    "import lxml.html as lh\n",
    "import requests\n",
    "from fbprophet import Prophet\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyo.init_notebook_mode(connected=True)\n",
    "cf.go_offline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cases_india=0\n",
    "recover_cases_india=0\n",
    "death_cases_india=0\n",
    "active_cases_india=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata():\n",
    "    url = 'https://www.mohfw.gov.in/' \n",
    "\n",
    "        # make a GET request to fetch the raw HTML content\n",
    "    web_content = requests.get(url).content\n",
    "\n",
    "        # parse the html content\n",
    "    soup = BeautifulSoup(web_content, \"html.parser\")\n",
    "\n",
    "        # remove any newlines and extra spaces from left and right\n",
    "    extract_contents = lambda row: [x.text.replace('\\n', '') for x in row] \n",
    "\n",
    "    stats = [] # initialize stats\n",
    "    all_rows = soup.find_all('tr') # find all table rows \n",
    "\n",
    "    for row in all_rows: \n",
    "        stat = extract_contents(row.find_all('td')) # find all data cells  \n",
    "            # notice that the data that we require is now a list of length 5\n",
    "        if len(stat) == 6: \n",
    "            stats.append(stat)\n",
    "\n",
    "        # now convert the data into a pandas dataframe for further processing\n",
    "    new_cols = [\"Sr.No\", \"States/UT\",\"Activecase\",\"Recovered\",\"Deceased\",\"Confirmed\"]\n",
    "    state_data = pd.DataFrame(data = stats, columns = new_cols)\n",
    "    state_data.drop(['Activecase'],axis=1,inplace=True)\n",
    "    state_data = state_data.iloc[:36,:]\n",
    "    state_data.tail(1).Recovered=\"0\"\n",
    "    state_data.tail(1).Deceased=\"0\"\n",
    "\n",
    "    #print(state_data)\n",
    "    return state_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images():\n",
    "    state_data = getdata()\n",
    "    dec=[]\n",
    "\n",
    "    for x in state_data['Deceased']:\n",
    "        x = x.replace('#','')\n",
    "        x = x.replace('*','')\n",
    "        dec.append(x)\n",
    "    state_data['Deceased']=dec\n",
    "    dec.clear()\n",
    "\n",
    "    for x in state_data['Confirmed']:\n",
    "        x = x.replace('#','')\n",
    "        x = x.replace('*','')\n",
    "        dec.append(x)\n",
    "    state_data['Confirmed']=dec\n",
    "    dec.clear()\n",
    "\n",
    "    for x in state_data['Recovered']:\n",
    "        x = x.replace('#','')\n",
    "        x = x.replace('*','')\n",
    "        dec.append(x)\n",
    "    state_data['Recovered']=dec\n",
    "    dec.clear()\n",
    "\n",
    "    for x in state_data['States/UT']:\n",
    "        x = x.replace('#','')\n",
    "        x = x.replace('*','')\n",
    "        dec.append(x)\n",
    "    state_data['States/UT']=dec\n",
    "    dec.clear()\n",
    "\n",
    "\n",
    "    # converting the 'string' data to 'int'\n",
    "    state_data['Confirmed'] = state_data['Confirmed'].map(int)\n",
    "    state_data['Recovered'] = state_data['Recovered'].map(int)\n",
    "    state_data['Deceased']  = state_data['Deceased'].map(int)\n",
    "    total_cases_india=state_data['Confirmed'].sum()\n",
    "    recover_cases_india=state_data['Recovered'].sum()\n",
    "    death_cases_india=state_data['Deceased'].sum()\n",
    "    state_data['Active Cases']=state_data['Confirmed']-(state_data['Deceased']+state_data['Recovered'])\n",
    "    active_cases_india = state_data['Active Cases'].sum()\n",
    "    cases_in_India = [total_cases_india,recover_cases_india,death_cases_india]\n",
    "    #plot1\n",
    "    state_data.sort_values(\"Confirmed\",ascending=False,inplace=True)\n",
    "    fig = px.bar(state_data,x='States/UT',y='Confirmed',color='Confirmed',width=700, height=500,text='Confirmed',title=\"Confirmed Covid19 Cases in Indian States\")\n",
    "    fig.write_html(\"static/india_state_confirm_case.html\")\n",
    "    \n",
    "    #plot2\n",
    "    state_data.sort_values(\"Active Cases\",ascending=False,inplace=True)\n",
    "    fig = px.bar(state_data,x='States/UT',y='Active Cases',color='Active Cases',width=700,height = 500,text='Active Cases')\n",
    "    fig.update_layout(title=\"Active Cases in Indian States\")\n",
    "    fig.write_html(\"static/india_state_active_case.html\")\n",
    "    \n",
    "    \n",
    "    #plot3\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=state_data['States/UT'], y=state_data['Confirmed'],mode='lines+markers',name='Confirmed Cases in each state',showlegend=True))\n",
    "    fig.add_trace(go.Scatter(x=state_data['States/UT'], y=state_data['Deceased'],mode='lines+markers',name='Deaths Cases in each state',showlegend=True))\n",
    "    fig.add_trace(go.Scatter(x=state_data['States/UT'], y=state_data['Recovered'],mode='lines+markers',name='Recovered Cases in each state',showlegend=True))\n",
    "    fig.update_layout(title=\"All State Analysis\",xaxis_title=\"States/UT\",yaxis_title=\"Number of people\")\n",
    "    #fig.show()\n",
    "    fig.write_html(\"static/india_states_analysis.html\")\n",
    "    \n",
    "    #dataset\n",
    "    f = open(\"indiageodata.json\")\n",
    "    counties = json.load(f)\n",
    "    \n",
    "    #plot4\n",
    "    fig = px.choropleth_mapbox(state_data, geojson=counties, locations='States/UT', color='Active Cases',\n",
    "                               color_continuous_scale=\"Viridis\",featureidkey=\"properties.NAME_1\",\n",
    "                           mapbox_style=\"carto-positron\",hover_data=[\"Confirmed\", \"Active Cases\",\"Recovered\",\"Deceased\"],\n",
    "                               zoom=3,center = {\"lat\": 20.5937, \"lon\": 78.9629},opacity=0.5,\n",
    "                               labels={'Active Cases':'Active Cases'})\n",
    "    fig.write_html('static/india_covidcases_map.html')\n",
    "    \n",
    "    \n",
    "    #webscrap world corona cases\n",
    "    import requests\n",
    "    req = requests.get(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\")\n",
    "    url_content = req.content\n",
    "    csv_file = open(r'owid-covid-data.csv','wb')\n",
    "\n",
    "    csv_file.write(url_content)\n",
    "    csv_file.close()\n",
    "    data = pd.read_csv(r'owid-covid-data.csv',parse_dates=True)\n",
    "    data_italy = data[(data.location=='Italy')]\n",
    "    data_us = data[(data.location=='United States')]\n",
    "    data_india = data[(data.location=='India')]\n",
    "    data_china = data[(data.location=='China')]\n",
    "    \n",
    "    \n",
    "    #plot6\n",
    "    fig=make_subplots(\n",
    "    rows=2,cols=2,\n",
    "    specs=[[{\"secondary_y\":True},{\"secondary_y\":True}],[{\"secondary_y\":True},{\"secondary_y\":True}]],\n",
    "    subplot_titles=(\"China\",\"Italy\",\"United States\",\"India\"))\n",
    "\n",
    "    fig.add_trace(go.Bar(x=data_china['date'],y=data_china['total_cases'],\n",
    "                        marker=dict(color=data_china['total_cases'],coloraxis=\"coloraxis\")),1,1)\n",
    "\n",
    "    fig.add_trace(go.Bar(x=data_italy['date'],y=data_italy['total_cases'],\n",
    "                        marker=dict(color=data_italy['total_cases'],coloraxis=\"coloraxis\")),1,2)\n",
    "\n",
    "    fig.add_trace(go.Bar(x=data_us['date'],y=data_us['total_cases'],\n",
    "                        marker=dict(color=data_us['total_cases'],coloraxis=\"coloraxis\")),2,1)\n",
    "\n",
    "    fig.add_trace(go.Bar(x=data_india['date'],y=data_india['total_cases'],\n",
    "                        marker=dict(color=data_india['total_cases'],coloraxis=\"coloraxis\")),2,2)\n",
    "\n",
    "\n",
    "\n",
    "    fig.update_layout(showlegend=False,title_text=\"Total Cases in 4 Countries\",xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Number of people\")\n",
    "\n",
    "    fig.update_layout(plot_bgcolor='rgb(169,169,169)')\n",
    "    fig.write_html(\"static/country_comparision_total_cases.html\")\n",
    "\n",
    "    #data\n",
    "    !kaggle datasets download -d sudalairajkumar/novel-corona-virus-2019-dataset --force\n",
    "    file_name = \"novel-corona-virus-2019-dataset.zip\"\n",
    "    # opening the zip file in READ mode \n",
    "    with ZipFile(file_name, 'r') as zip: \n",
    "        # extracting the file \n",
    "        zip.extract(\"covid_19_data.csv\")\n",
    "        zip.extract(\"time_series_covid_19_confirmed.csv\")\n",
    "    df=pd.read_csv(r'covid_19_data.csv',parse_dates=['Last Update'])\n",
    "    df.rename(columns={'ObservationDate':'Date','Country/Region':'Country'},inplace=True)\n",
    "    confirmed=df.groupby('Date').sum()['Confirmed'].reset_index()\n",
    "    death=df.groupby('Date').sum()['Deaths'].reset_index()\n",
    "    rec=df.groupby('Date').sum()['Recovered'].reset_index()\n",
    "    \n",
    "    #plot7\n",
    "    fig=go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=confirmed['Date'],y=confirmed['Confirmed'],mode='lines+markers',name='Confirmed',line=dict(color='blue',width=2)))\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=death['Date'],y=death['Deaths'],mode='lines+markers',name='Deaths',line=dict(color='red',width=2)))\n",
    "    fig.add_trace(go.Scatter(x=rec['Date'],y=rec['Recovered'],mode='lines+markers',name='Recovered',line=dict(color='green',width=2)))\n",
    "    fig.update_layout(title_text=\"covid 19 cases in world\",xaxis_title='Observation Date' ,yaxis_title='number of people')\n",
    "    fig.write_html(\"static/world_confirm_death_cured.html\")\n",
    "    \n",
    "    #data\n",
    "    df_confirmed=pd.read_csv(r'time_series_covid_19_confirmed.csv')\n",
    "    df_confirmed.rename(columns={'Country/Region':'Country'},inplace=True)\n",
    "    df_latlong=pd.merge(df,df_confirmed,on=['Country','Province/State'])\n",
    "    \n",
    "    \n",
    "    #plot9\n",
    "    fig=px.scatter_mapbox(df_latlong,lat=\"Lat\",lon=\"Long\",zoom=1,height=700)\n",
    "    fig.update_layout(title='Worldwide Corona Virus Cases')\n",
    "    fig.update_layout(mapbox_style=\"carto-positron\",mapbox_center_lon=0)\n",
    "    fig.update_layout(margin={\"r\":2,\"t\":50,\"l\":2,\"b\":0},xaxis_title = \"Observation Date\",yaxis_title='Corona Cases')\n",
    "    fig.write_html(\"static/world_cases_scatter_plot.html\")\n",
    "   \n",
    "    return total_cases_india,recover_cases_india,death_cases_india,active_cases_india  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "  url = 'https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'\n",
    "  url_cnf = 'https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "  # for confirmed cases overall\n",
    "  cnf = uReq(url_cnf)\n",
    "  pg_cnf = requests.get(url_cnf)\n",
    "  doc_cnf = lh.fromstring(pg_cnf.content)\n",
    "  cnf_elements = doc_cnf.xpath('//tr')\n",
    "  cnf.close()\n",
    "  # for deaths overall\n",
    "  client = uReq(url)\n",
    "  page = requests.get(url)\n",
    "  doc = lh.fromstring(page.content)\n",
    "  tr_elements = doc.xpath('//tr')\n",
    "  client.close()\n",
    "  # for confirmed cases\n",
    "  col_cnf=[]\n",
    "  i=0\n",
    "  #For each row, store each first element (header) and an empty list\n",
    "  for t in cnf_elements[0]:\n",
    "      i+=1\n",
    "      name=t.text_content()\n",
    "      #print ('%d:\"%s\"'%(i,name))\n",
    "      col_cnf.append((name,[]))\n",
    "  # for deaths\n",
    "  col=[]\n",
    "  i=0\n",
    "  #For each row, store each first element (header) and an empty list\n",
    "  for t in tr_elements[0]:\n",
    "      i+=1\n",
    "      name=t.text_content()\n",
    "      #print ('%d:\"%s\"'%(i,name))\n",
    "      col.append((name,[]))\n",
    "  # for confirmed cases\n",
    "\n",
    "  for j in range(1,len(cnf_elements)):\n",
    "    T=cnf_elements[j]\n",
    "    i=0\n",
    "    for t in T.iterchildren():\n",
    "          data=t.text_content() \n",
    "          if i>0:\n",
    "          #Convert any numerical value to integers\n",
    "              try:\n",
    "                  data=int(data)\n",
    "              except:\n",
    "                  pass\n",
    "          #Append the data to the empty list of the i'th column\n",
    "          col_cnf[i][1].append(data)\n",
    "          #Increment i for the next column\n",
    "          i+=1\n",
    "    # for deaths \n",
    "\n",
    "  for j in range(1,len(tr_elements)):\n",
    "    T=tr_elements[j]\n",
    "    i=0\n",
    "    for t in T.iterchildren():\n",
    "          data=t.text_content() \n",
    "          if i>0:\n",
    "          #Convert any numerical value to integers\n",
    "              try:\n",
    "                  data=int(data)\n",
    "              except:\n",
    "                  pass\n",
    "          #Append the data to the empty list of the i'th column\n",
    "          col[i][1].append(data)\n",
    "          #Increment i for the next column\n",
    "          i+=1\n",
    "\n",
    "  Dict={title:column for (title,column) in col}\n",
    "  df=pd.DataFrame(Dict)\n",
    "  d={title:column for (title,column) in col_cnf}\n",
    "  cnf=pd.DataFrame(d)\n",
    "  cnf.to_csv('time_series_cnf.csv')\n",
    "  cnf.rename(columns={'Country/Region':'Country'}, inplace=True)\n",
    "  col = ['Country','Lat','Long','Province/State']\n",
    "  cnf_india = cnf[cnf['Country'] == 'India'].drop(col,axis = 1).transpose().reset_index().drop(0,axis = 0)\n",
    "\n",
    "  cnf_india.rename(columns = {'index':'Date'}, inplace = True) \n",
    "  cnf_india.rename(columns = {131:'Confirmed'}, inplace = True) \n",
    "  fin_cnf = cnf_india\n",
    "  index = fin_cnf.index\n",
    "  length = len(index)\n",
    "  for i in range(1,length+1):\n",
    "    fin_cnf['Date'][i] = str(fin_cnf['Date'][i])\n",
    "    fin_cnf['Confirmed'][i] = (fin_cnf['Confirmed'][i])\n",
    "  fin_cnf.columns = ['ds','y']\n",
    "  fin_cnf['ds'] = pd.to_datetime(fin_cnf['ds'])\n",
    "  type(fin_cnf['ds'])\n",
    "  confirmed = fin_cnf\n",
    "\n",
    "  m = Prophet(interval_width=0.95,yearly_seasonality=True,daily_seasonality=True)\n",
    "  m.fit(confirmed)\n",
    "  future = m.make_future_dataframe(periods=7)\n",
    "  future.tail()\n",
    "  forecast = m.predict(future)\n",
    "  forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "\n",
    "  df.rename(columns={'Country/Region':'Country'}, inplace=True)\n",
    "  col = ['Country','Lat','Long','Province/State']\n",
    "  df =  df[df['Country'] == 'India'].drop(col,axis = 1).transpose().reset_index().drop(0,axis = 0)\n",
    "\n",
    "  df.rename(columns = {'index':'Date'}, inplace = True) \n",
    "  df.rename(columns = {131:'Death'}, inplace = True) \n",
    "\n",
    "  fin_df = df\n",
    "  index = df.index\n",
    "  length = len(index)\n",
    "  for i in range(1,length+1):\n",
    "    fin_df['Date'][i] = str(df['Date'][i])\n",
    "    fin_df['Death'][i] = (df['Death'][i])\n",
    "\n",
    "  fin_df.columns = ['ds','y']\n",
    "  fin_df['ds'] = pd.to_datetime(fin_cnf['ds'])\n",
    "\n",
    "  confirm = fin_df\n",
    "\n",
    "  m = Prophet(interval_width=0.95,yearly_seasonality=True,daily_seasonality=True)\n",
    "  m.fit(confirm)\n",
    "  future_death = m.make_future_dataframe(periods=7)\n",
    "  future_death.tail()\n",
    "  forecast_death = m.predict(future)\n",
    "  \n",
    "\n",
    "\n",
    "  index = forecast_death.index\n",
    "  length1 = len(index)\n",
    "\n",
    "  death = []\n",
    "  conf = []\n",
    "\n",
    "  for i in range(length,length1):\n",
    "    death.append(forecast_death['yhat_lower'][i])\n",
    "    conf.append(forecast['yhat_lower'][i])\n",
    "  \n",
    "  forecast_death_7 = forecast_death.loc[length:len(forecast),['ds','yhat_lower']]\n",
    "  forecast_cnf_7 = forecast.loc[length:len(forecast),['ds','yhat_lower']]\n",
    "  forecast_death_7.to_csv('death_7.csv')\n",
    "  forecast_cnf_7.to_csv('conf_7.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask_ngrok import run_with_ngrok\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading novel-corona-virus-2019-dataset.zip to C:\\Users\\Akshat\\Desktop\\dataset used\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/1.11M [00:00<?, ?B/s]\n",
      " 90%|########9 | 1.00M/1.11M [00:01<00:00, 922kB/s]\n",
      "100%|##########| 1.11M/1.11M [00:01<00:00, 930kB/s]\n"
     ]
    }
   ],
   "source": [
    "total_cases_india,recover_cases_india,death_cases_india,active_cases_india = images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "death_pred = pd.read_csv(\"death_7.csv\")\n",
    "conf_pred = pd.read_csv(\"conf_7.csv\")\n",
    "conf_pred.drop(conf_pred.columns[[0]], axis = 1, inplace = True)\n",
    "conf_pred.rename(columns = {\"ds\": \"Date\", \"yhat_lower\":\"Predicted Cases\"}, inplace = True)\n",
    "death_pred.drop(death_pred.columns[[0]], axis = 1, inplace = True)\n",
    "death_pred.rename(columns = {\"ds\": \"Date\", \"yhat_lower\":\"Predicted Cases\"}, inplace = True)\n",
    "conf_pred['Predicted Cases'] = conf_pred['Predicted Cases'].map(int)\n",
    "death_pred['Predicted Cases'] = death_pred['Predicted Cases'].map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Running on http://b5aa3c9e2822.ngrok.io\n",
      " * Traffic stats available on http://127.0.0.1:4040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [30/May/2020 21:05:35] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask_ngrok import run_with_ngrok\n",
    "\n",
    "\n",
    "\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "import pickle\n",
    "\n",
    "app = Flask(__name__)\n",
    "run_with_ngrok(app)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html',total_cases=total_cases_india, recovered_cases = recover_cases_india,death_cases=death_cases_india,active_cases=active_cases_india)\n",
    "\n",
    "@app.route('/india')\n",
    "def india():\n",
    "    return render_template('index.html',total_cases=total_cases_india, recovered_cases = recover_cases_india,death_cases=death_cases_india,active_cases=active_cases_india)\n",
    "\n",
    "\n",
    "@app.route('/worlddata')\n",
    "def worlddata():\n",
    "    return render_template('worldcase.html')\n",
    "\n",
    "\n",
    "@app.route('/info')\n",
    "def info():\n",
    "    return render_template('info.html')\n",
    "\n",
    "@app.route('/confirmcase')\n",
    "def confirmcase():\n",
    "    return render_template('predicted_confirm_cases.html',  tables=[conf_pred.to_html(classes='data')])\n",
    "\n",
    "@app.route('/deathcase')\n",
    "def deathcase():\n",
    "    return render_template('predicted_death_cases.html',  tables=[death_pred.to_html(classes='data')])\n",
    "\n",
    "@app.route('/helpline')\n",
    "def helpline():\n",
    "    return render_template('helpline.html')\n",
    "\n",
    "@app.route('/twitter_analysis')\n",
    "def twitter_analysis():\n",
    "    return render_template('twitter analysis.html')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
